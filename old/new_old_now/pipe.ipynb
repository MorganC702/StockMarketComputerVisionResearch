{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eda809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../')\n",
    "from utils.load_ticker import load_ticker\n",
    "from utils.clean_data import clean_data\n",
    "\n",
    "df = load_ticker(\n",
    "    base_dir = \"../../parquet_minute/\", \n",
    "    time_col = \"Date\",\n",
    "    symbol_col=\"Symbol\",\n",
    "    seed = 42, \n",
    "    symbol= \"SPY\",\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "df_1m = clean_data(\n",
    "    df=df,\n",
    "    timestamp_col = \"Date\",\n",
    "    symbol_col = \"Symbol\",\n",
    "    drop_duplicate_rows = True,\n",
    "    drop_duplicate_cols = True,\n",
    "    drop_constant_columns = True,\n",
    "    drop_constant_rows = True,\n",
    "    replace_placeholders = True,\n",
    "    placeholders=(\"Null\", \"null\", \"NULL\", \"NaN\", \"nan\", \"NAN\", \"None\", \"none\", \"NONE\"),\n",
    "    fill_missing = True,\n",
    "    convert_numeric = True,\n",
    "    sort_by = \"timestamp\",\n",
    "    verbose = False,\n",
    ")\n",
    "\n",
    "# df_1m = df_1m.tail(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc658f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "output_path = \"resampled_data\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "\n",
    "df_1m[\"timestamp\"] = pd.to_datetime(df_1m[\"Date\"], utc=True)\n",
    "df_1m = df_1m.drop_duplicates(subset=\"timestamp\")\n",
    "df_1m = df_1m.set_index(\"timestamp\").sort_index()\n",
    "\n",
    "\n",
    "df_1m.to_csv(os.path.join(output_path, \"ohlcv_1m.csv\"))\n",
    "\n",
    "def resample_ohlc(df, rule):\n",
    "    required_cols = {\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"}\n",
    "    if not required_cols.issubset(df.columns):\n",
    "        raise ValueError(f\"Missing columns: {required_cols - set(df.columns)}\")\n",
    "    \n",
    "    df_resampled = df.resample(rule, label=\"right\", closed=\"right\").agg({\n",
    "        \"Open\": \"first\",\n",
    "        \"High\": \"max\",\n",
    "        \"Low\": \"min\",\n",
    "        \"Close\": \"last\",\n",
    "        \"Volume\": \"sum\"\n",
    "    }).dropna(how=\"any\")\n",
    "    \n",
    "    return df_resampled\n",
    "\n",
    "TIMEFRAMES = {\n",
    "    \"3m\": \"3min\",\n",
    "    \"5m\": \"5min\",\n",
    "    \"15m\": \"15min\",\n",
    "    \"1h\": \"1h\",\n",
    "    \"4h\": \"4h\",\n",
    "    \"1d\": \"1d\"\n",
    "}\n",
    "\n",
    "resampled_dfs = {\n",
    "    tf: resample_ohlc(df_1m, rule) for tf, rule in TIMEFRAMES.items()\n",
    "}\n",
    "\n",
    "for tf, df in resampled_dfs.items():\n",
    "    df.to_csv(os.path.join(output_path, f\"ohlcv_{tf}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83917b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Levels saved for 15m: 5581 levels\n",
      "✅ Levels saved for 1h: 1440 levels\n",
      "✅ Levels saved for 1m: 80877 levels\n",
      "✅ Levels saved for 3m: 26909 levels\n",
      "✅ Levels saved for 1d: 207 levels\n",
      "✅ Levels saved for 5m: 16248 levels\n",
      "✅ Levels saved for 4h: 477 levels\n"
     ]
    }
   ],
   "source": [
    "# detect_levels.py\n",
    "import os\n",
    "import pandas as pd\n",
    "from StockMarketComputerVisionResearch.new.new_old_now.detect_break_levels import detect_break_levels\n",
    "\n",
    "# Input/output paths\n",
    "input_path = \"resampled_data\"\n",
    "level_output_path = \"break_level_data\"\n",
    "os.makedirs(level_output_path, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(input_path):\n",
    "    if file.endswith(\".csv\") and file.startswith(\"ohlcv_\"):\n",
    "        tf = file.replace(\"ohlcv_\", \"\").replace(\".csv\", \"\")\n",
    "        df = pd.read_csv(os.path.join(input_path, file), index_col=0, parse_dates=True)\n",
    "\n",
    "        break_levels = detect_break_levels(df)\n",
    "        break_levels.to_csv(os.path.join(level_output_path, f\"break_levels_{tf}.csv\"), index=False)\n",
    "\n",
    "        print(f\"✅ Levels saved for {tf}: {len(break_levels)} levels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959a4aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Breaks saved for 15m: 5441 events\n",
      "✅ Breaks saved for 1h: 1364 events\n",
      "✅ Breaks saved for 1m: 80362 events\n",
      "✅ Breaks saved for 3m: 26620 events\n",
      "✅ Breaks saved for 1d: 187 events\n",
      "✅ Breaks saved for 5m: 16001 events\n",
      "✅ Breaks saved for 4h: 435 events\n"
     ]
    }
   ],
   "source": [
    "# track_breaks.py\n",
    "import os\n",
    "import pandas as pd\n",
    "from StockMarketComputerVisionResearch.new.new_old_now.detect_break_levels import track_break_events  # NEW FUNCTION\n",
    "\n",
    "input_path = \"resampled_data\"\n",
    "level_input_path = \"break_level_data\"\n",
    "event_output_path = \"break_event_data\"\n",
    "os.makedirs(event_output_path, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(input_path):\n",
    "    if file.endswith(\".csv\") and file.startswith(\"ohlcv_\"):\n",
    "        tf = file.replace(\"ohlcv_\", \"\").replace(\".csv\", \"\")\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(input_path, file), index_col=0, parse_dates=True)\n",
    "        levels_df_path = os.path.join(level_input_path, f\"break_levels_{tf}.csv\")\n",
    "        \n",
    "        if not os.path.exists(levels_df_path):\n",
    "            print(f\"⚠️ Skipping {tf} — no levels file found.\")\n",
    "            continue\n",
    "        \n",
    "        levels_df = pd.read_csv(levels_df_path, parse_dates=[\"level_time\"])\n",
    "        \n",
    "        # ✅ Use the STACK version\n",
    "        break_events = track_break_events(df, levels_df)\n",
    "        \n",
    "        break_events.to_csv(\n",
    "            os.path.join(event_output_path, f\"break_events_{tf}.csv\"),\n",
    "            index=False\n",
    "        )\n",
    "\n",
    "        print(f\"✅ Breaks saved for {tf}: {len(break_events)} events\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efff0579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded timeframes: ['15m', '1d', '1h', '1m', '3m', '4h', '5m']\n",
      "🧠 Using base TF: 15m, Rendering 33792 frames\n",
      "🖼️ Rendered 0/33792 frames\n",
      "🖼️ Rendered 100/33792 frames\n",
      "🖼️ Rendered 200/33792 frames\n",
      "🖼️ Rendered 300/33792 frames\n",
      "🖼️ Rendered 400/33792 frames\n",
      "🖼️ Rendered 500/33792 frames\n",
      "🖼️ Rendered 600/33792 frames\n",
      "🖼️ Rendered 700/33792 frames\n",
      "🖼️ Rendered 800/33792 frames\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     16\u001b[39m label_to_id = {\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprice\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0\u001b[39m,\n\u001b[32m     18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msupport\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m,\n\u001b[32m     19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mresistance\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m2\u001b[39m\n\u001b[32m     20\u001b[39m }\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Generate break level visualizations\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mgenerate_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcandle_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbreak_levels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbreak_events\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_root\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m640\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdot_radius\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\n\u001b[32m     30\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data-science/MSDSResearchProjects/StockMarketComputerVisionResearch/new/generate_images.py:64\u001b[39m, in \u001b[36mgenerate_images\u001b[39m\u001b[34m(candle_data, break_levels, break_events, output_root, image_size, dot_radius, max_trail_length, price_scale)\u001b[39m\n\u001b[32m     59\u001b[39m broken = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m events_df.empty:\n\u001b[32m     61\u001b[39m     match = events_df[\n\u001b[32m     62\u001b[39m         (events_df[\u001b[33m\"\u001b[39m\u001b[33mlevel_price\u001b[39m\u001b[33m\"\u001b[39m] == level_price) &\n\u001b[32m     63\u001b[39m         (events_df[\u001b[33m\"\u001b[39m\u001b[33mbreak_type\u001b[39m\u001b[33m\"\u001b[39m] == level_type) &\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         (\u001b[43mevents_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbreak_time\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mts\u001b[49m)\n\u001b[32m     65\u001b[39m     ]\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m match.empty:\n\u001b[32m     67\u001b[39m         broken = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data-science/MSDSResearchProjects/.venv/lib/python3.13/site-packages/pandas/core/ops/common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data-science/MSDSResearchProjects/.venv/lib/python3.13/site-packages/pandas/core/arraylike.py:52\u001b[39m, in \u001b[36mOpsMixin.__le__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__le__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__le__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mle\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data-science/MSDSResearchProjects/.venv/lib/python3.13/site-packages/pandas/core/series.py:6132\u001b[39m, in \u001b[36mSeries._cmp_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6128\u001b[39m rvalues = extract_array(other, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   6130\u001b[39m res_values = ops.comparison_op(lvalues, rvalues, op)\n\u001b[32m-> \u001b[39m\u001b[32m6132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_construct_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mres_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data-science/MSDSResearchProjects/.venv/lib/python3.13/site-packages/pandas/core/series.py:6242\u001b[39m, in \u001b[36mSeries._construct_result\u001b[39m\u001b[34m(self, result, name)\u001b[39m\n\u001b[32m   6239\u001b[39m \u001b[38;5;66;03m# TODO: result should always be ArrayLike, but this fails for some\u001b[39;00m\n\u001b[32m   6240\u001b[39m \u001b[38;5;66;03m#  JSONArray tests\u001b[39;00m\n\u001b[32m   6241\u001b[39m dtype = \u001b[38;5;28mgetattr\u001b[39m(result, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m6242\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_constructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   6243\u001b[39m out = out.__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   6245\u001b[39m \u001b[38;5;66;03m# Set the result's name after __finalize__ is called because __finalize__\u001b[39;00m\n\u001b[32m   6246\u001b[39m \u001b[38;5;66;03m#  would set it back to self.name\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data-science/MSDSResearchProjects/.venv/lib/python3.13/site-packages/pandas/core/series.py:586\u001b[39m, in \u001b[36mSeries.__init__\u001b[39m\u001b[34m(self, data, index, dtype, name, copy, fastpath)\u001b[39m\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    584\u001b[39m     data = sanitize_array(data, index, dtype, copy)\n\u001b[32m--> \u001b[39m\u001b[32m586\u001b[39m     manager = \u001b[43m_get_option\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmode.data_manager\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    587\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33mblock\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    588\u001b[39m         data = SingleBlockManager.from_array(data, index, refs=refs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data-science/MSDSResearchProjects/.venv/lib/python3.13/site-packages/pandas/_config/config.py:146\u001b[39m, in \u001b[36m_get_option\u001b[39m\u001b[34m(pat, silent)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_option\u001b[39m(pat: \u001b[38;5;28mstr\u001b[39m, silent: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     key = \u001b[43m_get_single_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m     \u001b[38;5;66;03m# walk the nested dict\u001b[39;00m\n\u001b[32m    149\u001b[39m     root, k = _get_root(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data-science/MSDSResearchProjects/.venv/lib/python3.13/site-packages/pandas/_config/config.py:140\u001b[39m, in \u001b[36m_get_single_key\u001b[39m\u001b[34m(pat, silent)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silent:\n\u001b[32m    138\u001b[39m     _warn_if_deprecated(key)\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m key = \u001b[43m_translate_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m key\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/data-science/MSDSResearchProjects/.venv/lib/python3.13/site-packages/pandas/_config/config.py:676\u001b[39m, in \u001b[36m_translate_key\u001b[39m\u001b[34m(key)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    667\u001b[39m \u001b[33;03m    Retrieves the option metadata if `key` is a registered option.\u001b[39;00m\n\u001b[32m    668\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    671\u001b[39m \u001b[33;03m    RegisteredOption (namedtuple) if key is deprecated, None otherwise\u001b[39;00m\n\u001b[32m    672\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    673\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _registered_options.get(key)\n\u001b[32m--> \u001b[39m\u001b[32m676\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_translate_key\u001b[39m(key: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    677\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    678\u001b[39m \u001b[33;03m    if key id deprecated and a replacement key defined, will return the\u001b[39;00m\n\u001b[32m    679\u001b[39m \u001b[33;03m    replacement key, otherwise returns `key` as - is\u001b[39;00m\n\u001b[32m    680\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    681\u001b[39m     d = _get_deprecated_option(key)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from StockMarketComputerVisionResearch.new.new_old_now.load_all_structure_data import load_all_structure_data\n",
    "from StockMarketComputerVisionResearch.new.new_old_now.generate_images import generate_images\n",
    "\n",
    "\n",
    "# Load everything\n",
    "candle_data, break_levels, break_events = load_all_structure_data(\n",
    "    resampled_dir=\"resampled_data\",\n",
    "    level_dir=\"break_level_data\",\n",
    "    event_dir=\"break_event_data\"\n",
    ")\n",
    "\n",
    "# Output folder for images\n",
    "output_dir = \"dataset\"\n",
    "\n",
    "label_to_id = {\n",
    "    \"price\": 0,\n",
    "    \"support\": 1,\n",
    "    \"resistance\": 2\n",
    "}\n",
    "\n",
    "# Generate break level visualizations\n",
    "generate_images(\n",
    "    candle_data,\n",
    "    break_levels,\n",
    "    break_events,\n",
    "    output_root=\"dataset\",\n",
    "    image_size=(640, 640),\n",
    "    dot_radius= 2\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93af9aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Video saved: ./dataset/videos/tf_2025-09-23_07-03-08.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def export_tf_video(\n",
    "    root_dir=\"./dataset\",\n",
    "    timeframes_top=(\"1m\", \"3m\", \"5m\", \"15m\"),\n",
    "    timeframes_bottom=(\"1h\", \"4h\", \"1d\"),\n",
    "    output_file=None,\n",
    "    fps=10,\n",
    "    scale=0.7,\n",
    "):\n",
    "    all_timeframes = timeframes_top + timeframes_bottom\n",
    "\n",
    "    if output_file is None:\n",
    "        ts = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        output_file = f\"{root_dir}/videos/tf_{ts}.mp4\"\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "    files = {\n",
    "        tf: sorted(glob.glob(os.path.join(root_dir, tf, \"images\", \"*.png\")))\n",
    "        for tf in all_timeframes\n",
    "    }\n",
    "    num_frames = min(len(lst) for lst in files.values() if lst)\n",
    "\n",
    "    if num_frames == 0:\n",
    "        raise ValueError(\"❌ No frames found in one or more timeframe folders!\")\n",
    "\n",
    "    # Read one sample to determine base height\n",
    "    sample = cv2.imread(files[all_timeframes[0]][0])\n",
    "    if sample is None:\n",
    "        raise ValueError(\"❌ Could not load sample image.\")\n",
    "\n",
    "    base_height = int(sample.shape[0] * scale)\n",
    "    title_height = 30\n",
    "    chart_height = base_height + title_height\n",
    "\n",
    "    # Frame processing with title and black border\n",
    "    def process_frame(path, label):\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            return None\n",
    "        if scale != 1.0:\n",
    "            img = cv2.resize(img, (int(img.shape[1] * scale), int(img.shape[0] * scale)))\n",
    "        h, w = img.shape[:2]\n",
    "        img = cv2.resize(img, (int(w * base_height / h), base_height))\n",
    "\n",
    "        # Title bar\n",
    "        title_bar = np.full((title_height, img.shape[1], 3), 255, dtype=np.uint8)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        text_size = cv2.getTextSize(label, font, 0.6, 1)[0]\n",
    "        text_x = (title_bar.shape[1] - text_size[0]) // 2\n",
    "        text_y = (title_height + text_size[1]) // 2\n",
    "        cv2.putText(title_bar, label, (text_x, text_y), font, 0.6, (0, 0, 0), 1)\n",
    "\n",
    "        # Stack and draw border\n",
    "        combined = np.vstack([title_bar, img])\n",
    "        cv2.rectangle(combined, (0, 0), (combined.shape[1] - 1, combined.shape[0] - 1), (0, 0, 0), 1)\n",
    "        return combined\n",
    "\n",
    "    # Determine output width\n",
    "    top_width = sum(process_frame(files[tf][0], tf).shape[1] for tf in timeframes_top)\n",
    "    bot_width = sum(process_frame(files[tf][0], tf).shape[1] for tf in timeframes_bottom)\n",
    "    out_width = max(top_width, bot_width)\n",
    "    out_height = chart_height * 2\n",
    "\n",
    "    # Init video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_file, fourcc, fps, (out_width, out_height))\n",
    "\n",
    "    # Frame loop\n",
    "    for i in range(num_frames):\n",
    "        row_imgs = []\n",
    "        for tf_group in [timeframes_top, timeframes_bottom]:\n",
    "            frames = []\n",
    "            for tf in tf_group:\n",
    "                img = process_frame(files[tf][i], tf)\n",
    "                if img is not None:\n",
    "                    frames.append(img)\n",
    "            if frames:\n",
    "                row = np.hstack(frames)\n",
    "                if row.shape[1] < out_width:\n",
    "                    pad = np.full((chart_height, out_width - row.shape[1], 3), 255, dtype=np.uint8)\n",
    "                    row = np.hstack([row, pad])\n",
    "                row_imgs.append(row)\n",
    "\n",
    "        full_frame = np.vstack(row_imgs)\n",
    "        out.write(full_frame)\n",
    "\n",
    "    out.release()\n",
    "    print(f\"✅ Video saved: {output_file}\")\n",
    "\n",
    "\n",
    "# ✅ Run this cell in Jupyter\n",
    "export_tf_video(fps=10, scale=0.6)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
