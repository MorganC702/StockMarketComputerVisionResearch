{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acbeefff",
   "metadata": {},
   "source": [
    "```-\n",
    "File:           logistic_regression_baseline.ipynb\n",
    "Description:    Logistic Regression for baseline on raw data features. \n",
    "Author:         Morgan Cooper\n",
    "Created:        2025-09-01\n",
    "Updated:        2025-09-09\n",
    "\n",
    "Notes:\n",
    "Use this as a baseline for comparison with the resnet classifier model. \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8d6830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.45      0.46       566\n",
      "           1       0.54      0.57      0.56       654\n",
      "\n",
      "    accuracy                           0.51      1220\n",
      "   macro avg       0.51      0.51      0.51      1220\n",
      "weighted avg       0.51      0.51      0.51      1220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"../../data/ohlc_images/window=180/meta.csv\")\n",
    "\n",
    "X = df.drop(columns=[\"path\", \"label\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ---- Sequential splits ----\n",
    "n = len(df)\n",
    "train_end = int(0.7 * n)\n",
    "val_end   = int(0.85 * n)\n",
    "\n",
    "X_train, y_train = X_scaled[:train_end], y[:train_end]\n",
    "X_val,   y_val   = X_scaled[train_end:val_end], y[train_end:val_end]\n",
    "X_test,  y_test  = X_scaled[val_end:], y[val_end:]\n",
    "\n",
    "# ---- Train logistic regression ----\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ---- Evaluate on test ----\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a8c0276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST BINNING STATS (sorted by confidence):\n",
      "   bin_pctile  avg_proba  accuracy  num_total  num_won\n",
      "0        100%   0.707896  0.475410         61       29\n",
      "1         95%   0.621833  0.573770         61       35\n",
      "2         90%   0.596748  0.540984         61       33\n",
      "3         85%   0.578408  0.655738         61       40\n",
      "4         80%   0.562541  0.475410         61       29\n",
      "5         75%   0.551194  0.540984         61       33\n",
      "6         70%   0.541677  0.557377         61       34\n",
      "7         65%   0.533391  0.459016         61       28\n",
      "8         60%   0.523076  0.639344         61       39\n",
      "9         55%   0.514067  0.557377         61       34\n",
      "10        50%   0.506228  0.491803         61       30\n",
      "11        45%   0.497628  0.409836         61       39\n",
      "12        40%   0.487158  0.540984         61       28\n",
      "13        35%   0.477051  0.459016         61       33\n",
      "14        30%   0.465191  0.491803         61       31\n",
      "15        25%   0.451894  0.459016         61       33\n",
      "16        20%   0.436488  0.409836         61       36\n",
      "17        15%   0.410594  0.491803         61       31\n",
      "18        10%   0.376550  0.524590         61       29\n",
      "19         5%   0.286116  0.508197         61       30\n"
     ]
    }
   ],
   "source": [
    "proba = model.predict_proba(X_test)[:, 1]\n",
    "preds = model.predict(X_test)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"proba\": proba,\n",
    "    \"pred\": preds,\n",
    "    \"label\": y_test\n",
    "})\n",
    "\n",
    "results[\"bin\"] = pd.qcut(results[\"proba\"], q=20, labels=False)\n",
    "\n",
    "bin_stats = results.groupby(\"bin\").agg(\n",
    "    avg_proba=(\"proba\", \"mean\"),\n",
    "    accuracy=(\"pred\", lambda x: (x == results.loc[x.index, \"label\"]).mean()),\n",
    "    win_rate=(\"label\", \"mean\"),\n",
    "    count=(\"label\", \"count\")\n",
    ").reset_index()\n",
    "\n",
    "bin_stats[\"num_won\"] = (bin_stats[\"win_rate\"] * bin_stats[\"count\"]).astype(int)\n",
    "bin_stats = bin_stats.rename(columns={\"count\": \"num_total\"})\n",
    "\n",
    "bin_stats_sorted = bin_stats.sort_values(\"avg_proba\", ascending=False).reset_index(drop=True)\n",
    "bin_stats_sorted[\"bin_pctile\"] = bin_stats_sorted.index.map(lambda i: f\"{(20 - i) * 5}%\")\n",
    "final = bin_stats_sorted[[\"bin_pctile\", \"avg_proba\", \"accuracy\", \"num_total\", \"num_won\"]]\n",
    "\n",
    "print(\"\\nTEST BINNING STATS (sorted by confidence):\")\n",
    "print(final)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
