{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea858051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from pipeline.aggregator import TimeframeAggregator\n",
    "from data_gen.generate_plain_img import ImageGenerator  # plain candles + YOLO boxes\n",
    "\n",
    "# --- Config ---\n",
    "csv_path = \"./data/agg_data/fx/C:EURUSD_1m_last1y.csv\"\n",
    "save_dir = Path(\"./dataset\")\n",
    "\n",
    "timeframes = [\"5m\", \"15m\", \"1h\", \"4h\", \"1d\"]\n",
    "candle_limits = {tf: 60 for tf in timeframes}  # always 60 candles per TF\n",
    "image_size = (640, 640)\n",
    "\n",
    "# --- Setup ---\n",
    "df = pd.read_csv(csv_path, parse_dates=[\"timestamp\"])\n",
    "buffer = deque(maxlen=60 * 24 * 60 + 100)\n",
    "aggregator = TimeframeAggregator(buffer)\n",
    "image_gen = ImageGenerator(candle_limits, image_size=image_size)\n",
    "\n",
    "# --- Warmup with first 60 days of 1m data ---\n",
    "start_index = 60 * 24 * 60  # 60 days * 24h * 60m\n",
    "print(f\"[INFO] Warming up with first {start_index} minutes ({60} days)\")\n",
    "\n",
    "warmup_df = df.iloc[:start_index]\n",
    "for _, row in tqdm(warmup_df.iterrows(), total=len(warmup_df), desc=\"Warming buffer\"):\n",
    "    buffer.append(row.to_dict())\n",
    "    aggregator.resample_all(timeframes)\n",
    "\n",
    "print(\"[INFO] Warmup complete. Starting main generation loop.\")\n",
    "\n",
    "# --- Prepare meta.csv ---\n",
    "meta_path = save_dir / \"meta.csv\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "header = [\"timestamp\", \"close\"]\n",
    "for tf in timeframes:\n",
    "    header.append(f\"{tf}_img\")\n",
    "    header.append(f\"{tf}_lbl\")\n",
    "\n",
    "with open(meta_path, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=header)\n",
    "    writer.writeheader()\n",
    "\n",
    "# --- Main loop (forward from day 60) ---\n",
    "for i, row in tqdm(df.iloc[start_index:].iterrows(),\n",
    "                   total=len(df) - start_index,\n",
    "                   desc=\"Generating images (every 5m, 60-bar windows per TF)\"):\n",
    "    bar = row.to_dict()\n",
    "    buffer.append(bar)\n",
    "\n",
    "    resampled = aggregator.resample_all(timeframes)\n",
    "    timestamp = pd.to_datetime(row[\"timestamp\"])\n",
    "    close_price = row[\"close\"]\n",
    "\n",
    "    # Only produce outputs on 5m boundaries\n",
    "    if timestamp != timestamp.floor(\"5min\"):\n",
    "        continue\n",
    "\n",
    "    tf_image_paths = {}\n",
    "    for tf in timeframes:\n",
    "        df_tf = resampled[tf]\n",
    "        if df_tf.empty:\n",
    "            continue\n",
    "\n",
    "        # Always grab up to 60 candles (partial if fewer)\n",
    "        window = df_tf.tail(min(len(df_tf), candle_limits[tf]))\n",
    "\n",
    "        img_path = save_dir / \"images\" / tf / f\"{timestamp}.png\"\n",
    "        lbl_path = save_dir / \"labels\" / tf / f\"{timestamp}.txt\"\n",
    "\n",
    "        img_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        lbl_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        image_gen.generate_image(tf, window, str(img_path))\n",
    "\n",
    "        tf_image_paths[f\"{tf}_img\"] = str(img_path)\n",
    "        tf_image_paths[f\"{tf}_lbl\"] = str(lbl_path)\n",
    "\n",
    "    # Write CSV row even if some TFs are missing (they’ll just be blank)\n",
    "    row_out = {\"timestamp\": timestamp, \"close\": close_price}\n",
    "    row_out.update(tf_image_paths)\n",
    "\n",
    "    with open(meta_path, \"a\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=header)\n",
    "        writer.writerow(row_out)\n",
    "\n",
    "print(f\"[✅ DONE] Meta written (every 5m, all TFs, partial candles allowed) to {meta_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1e921b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67344b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# --- Settings ---\n",
    "SOURCE_IMAGE_DIR = \"./dataset/images\"\n",
    "SOURCE_LABEL_DIR = \"./dataset/labels\"\n",
    "OUTPUT_BASE_DIR = \"./img_dataset\"\n",
    "\n",
    "TRAIN_SPLIT = 0.7\n",
    "VAL_SPLIT = 0.2\n",
    "TEST_SPLIT = 0.1\n",
    "MAX_IMAGES = 200_000\n",
    "\n",
    "# --- Collect all image paths (sorted order) ---\n",
    "image_paths = sorted(\n",
    "    glob.glob(f\"{SOURCE_IMAGE_DIR}/**/*.png\", recursive=True) +\n",
    "    glob.glob(f\"{SOURCE_IMAGE_DIR}/**/*.jpg\", recursive=True)\n",
    ")\n",
    "\n",
    "# --- Limit to MAX_IMAGES ---\n",
    "total = min(len(image_paths), MAX_IMAGES)\n",
    "image_paths = image_paths[:total]\n",
    "\n",
    "# --- Calculate split indices ---\n",
    "n_train = int(total * TRAIN_SPLIT)\n",
    "n_val = int(total * VAL_SPLIT)\n",
    "n_test = total - n_train - n_val\n",
    "\n",
    "train_imgs = image_paths[:n_train]\n",
    "val_imgs = image_paths[n_train:n_train + n_val]\n",
    "test_imgs = image_paths[n_train + n_val:]\n",
    "\n",
    "splits = {\n",
    "    \"train\": train_imgs,\n",
    "    \"val\": val_imgs,\n",
    "    \"test\": test_imgs\n",
    "}\n",
    "\n",
    "# --- Copy files with timeframe in name ---\n",
    "for split, paths in splits.items():\n",
    "    for img_path in paths:\n",
    "        relative_img_path = os.path.relpath(img_path, SOURCE_IMAGE_DIR)\n",
    "        tf = relative_img_path.split(os.sep)[0]  # timeframe (e.g. \"1h\")\n",
    "\n",
    "        filename = os.path.basename(img_path)\n",
    "        new_filename = f\"{tf}_{filename}\"\n",
    "\n",
    "        img_out_dir = os.path.join(OUTPUT_BASE_DIR, \"images\", split)\n",
    "        lbl_out_dir = os.path.join(OUTPUT_BASE_DIR, \"labels\", split)\n",
    "        os.makedirs(img_out_dir, exist_ok=True)\n",
    "        os.makedirs(lbl_out_dir, exist_ok=True)\n",
    "\n",
    "        # Copy image\n",
    "        shutil.copy(img_path, os.path.join(img_out_dir, new_filename))\n",
    "\n",
    "        # Copy label if exists\n",
    "        label_rel_path = os.path.splitext(relative_img_path)[0] + \".txt\"\n",
    "        label_full_path = os.path.join(SOURCE_LABEL_DIR, label_rel_path)\n",
    "\n",
    "        if os.path.exists(label_full_path):\n",
    "            new_label_name = os.path.splitext(new_filename)[0] + \".txt\"\n",
    "            shutil.copy(label_full_path, os.path.join(lbl_out_dir, new_label_name))\n",
    "        else:\n",
    "            print(f\"⚠️ Label not found for: {img_path}\")\n",
    "\n",
    "print(\"✅ Dataset split complete. Filenames now include timeframe.\")\n",
    "print(f\"Total: {total} | Train: {len(train_imgs)} | Val: {len(val_imgs)} | Test: {len(test_imgs)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402d8781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor\n",
    "\n",
    "from env.trading_env import TradingEnv\n",
    "from models.yolo_extractor import CustomYOLOPolicy\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# writer = SummaryWriter(log_dir=\"./logs/custom\")\n",
    "\n",
    "\n",
    "\n",
    "# --- Load your meta.csv ---\n",
    "meta_df = pd.read_csv(\"./dataset/meta.csv\", parse_dates=[\"timestamp\"])\n",
    "\n",
    "# --- Create your environment ---\n",
    "def make_env():\n",
    "    def _init():\n",
    "        env = TradingEnv(meta_df)\n",
    "        env = Monitor(env)  # Wrap with Monitor to log rewards\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "# Wrap in vectorized and monitored env\n",
    "vec_env = DummyVecEnv([make_env()])\n",
    "vec_env = VecMonitor(vec_env)  # Logs mean reward per episode\n",
    "\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "\n",
    "vec_env = VecNormalize(vec_env, norm_obs=True, norm_reward=True, clip_reward=10.0)\n",
    "\n",
    "# --- Create PPO model ---\n",
    "model = PPO(\n",
    "    policy=CustomYOLOPolicy,\n",
    "    env=vec_env,\n",
    "    verbose=1,\n",
    "    n_steps=128,\n",
    "    batch_size=32,\n",
    "    learning_rate=3e-4,\n",
    "    ent_coef=0.01,\n",
    "    tensorboard_log=\"./logs\"\n",
    ")\n",
    "\n",
    "# After defining your model:\n",
    "# callback = RewardLoggingCallback(writer=writer)\n",
    "\n",
    "\n",
    "# --- Train the model ---\n",
    "\n",
    "model.learn(total_timesteps=100000)\n",
    "\n",
    "vec_env.save(\"vec_normalize.pkl\")\n",
    "\n",
    "# --- Save it ---\n",
    "model.save(\"ppo-yolo-trading\")\n",
    "print(\"✅ Training complete. Model saved to: ppo-yolo-trading\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
