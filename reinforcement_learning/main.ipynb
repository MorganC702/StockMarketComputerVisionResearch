{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea858051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Warming up with first 86400 minutes (60 days)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warming buffer: 100%|██████████| 86400/86400 [1:03:56<00:00, 22.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Warmup complete. Starting main generation loop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating images (every 5m, 60-bar windows per TF): 100%|██████████| 281907/281907 [7:50:49<00:00,  9.98it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✅ DONE] Meta written with simplified filenames to dataset/meta.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from pipeline.aggregator import TimeframeAggregator\n",
    "from data_gen.generate_plain_img import ImageGenerator  # plain candles + YOLO boxes\n",
    "\n",
    "# --- Config ---\n",
    "csv_path = \"./data/agg_data/fx/C:EURUSD_1m_last1y.csv\"\n",
    "save_dir = Path(\"./dataset\")\n",
    "\n",
    "timeframes = [\"5m\", \"15m\", \"1h\", \"4h\", \"1d\"]\n",
    "candle_limits = {tf: 60 for tf in timeframes}  # always 60 candles per TF\n",
    "image_size = (640, 640)\n",
    "\n",
    "# --- Setup ---\n",
    "df = pd.read_csv(csv_path, parse_dates=[\"timestamp\"])\n",
    "buffer = deque(maxlen=60 * 24 * 60 + 100)\n",
    "aggregator = TimeframeAggregator(buffer)\n",
    "image_gen = ImageGenerator(candle_limits, image_size=image_size)\n",
    "\n",
    "# --- Warmup with first N minutes ---\n",
    "start_index = 60 * 24 * 60  # 60 days * 24h * 60m\n",
    "print(f\"[INFO] Warming up with first {start_index} minutes ({60} days)\")\n",
    "\n",
    "warmup_df = df.iloc[:start_index]\n",
    "for _, row in tqdm(warmup_df.iterrows(), total=len(warmup_df), desc=\"Warming buffer\"):\n",
    "    buffer.append(row.to_dict())\n",
    "    aggregator.resample_all(timeframes)\n",
    "\n",
    "print(\"[INFO] Warmup complete. Starting main generation loop.\")\n",
    "\n",
    "# --- Prepare meta.csv ---\n",
    "meta_path = save_dir / \"meta.csv\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "header = [\"id\", \"timestamp\", \"close\"]\n",
    "for tf in timeframes:\n",
    "    header.append(f\"{tf}_img\")\n",
    "    header.append(f\"{tf}_lbl\")\n",
    "\n",
    "with open(meta_path, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=header)\n",
    "    writer.writeheader()\n",
    "\n",
    "# --- Main loop ---\n",
    "file_index = 0  # Counter for generating unique file IDs\n",
    "\n",
    "for i, row in tqdm(df.iloc[start_index:].iterrows(),\n",
    "                   total=len(df) - start_index,\n",
    "                   desc=\"Generating images (every 5m, 60-bar windows per TF)\"):\n",
    "    bar = row.to_dict()\n",
    "    buffer.append(bar)\n",
    "\n",
    "    resampled = aggregator.resample_all(timeframes)\n",
    "    timestamp = pd.to_datetime(row[\"timestamp\"])\n",
    "    close_price = row[\"close\"]\n",
    "\n",
    "    # Only produce outputs on 5m boundaries\n",
    "    if timestamp != timestamp.floor(\"5min\"):\n",
    "        continue\n",
    "\n",
    "    file_index += 1\n",
    "    file_id = f\"{file_index:06d}\"  # e.g. \"000001\"\n",
    "\n",
    "    tf_image_paths = {}\n",
    "    for tf in timeframes:\n",
    "        df_tf = resampled[tf]\n",
    "        if df_tf.empty:\n",
    "            continue\n",
    "\n",
    "        # Always grab up to 60 candles (partial if fewer)\n",
    "        window = df_tf.tail(min(len(df_tf), candle_limits[tf]))\n",
    "\n",
    "        img_path = save_dir / \"images\" / tf / f\"{file_id}.png\"\n",
    "        lbl_path = save_dir / \"labels\" / tf / f\"{file_id}.txt\"\n",
    "\n",
    "        img_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        lbl_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        image_gen.generate_image(tf, window, str(img_path))\n",
    "\n",
    "        tf_image_paths[f\"{tf}_img\"] = str(img_path.relative_to(save_dir))\n",
    "        tf_image_paths[f\"{tf}_lbl\"] = str(lbl_path.relative_to(save_dir))\n",
    "\n",
    "    # Write CSV row even if some TFs are missing (they’ll just be blank)\n",
    "    row_out = {\n",
    "        \"id\": file_id,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"close\": close_price,\n",
    "        **tf_image_paths\n",
    "    }\n",
    "\n",
    "    with open(meta_path, \"a\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=header)\n",
    "        writer.writerow(row_out)\n",
    "\n",
    "print(f\"[✅ DONE] Meta written with simplified filenames to {meta_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67344b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset split complete. Filenames now include timeframe.\n",
      "Total: 200000 | Train: 140000 | Val: 40000 | Test: 20000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# --- Settings ---\n",
    "SOURCE_IMAGE_DIR = \"./dataset/images\"\n",
    "SOURCE_LABEL_DIR = \"./dataset/labels\"\n",
    "OUTPUT_BASE_DIR = \"./img_dataset\"\n",
    "\n",
    "TRAIN_SPLIT = 0.7\n",
    "VAL_SPLIT = 0.2\n",
    "TEST_SPLIT = 0.1\n",
    "MAX_IMAGES = 200_000\n",
    "\n",
    "# --- Collect all image paths (sorted order) ---\n",
    "image_paths = sorted(\n",
    "    glob.glob(f\"{SOURCE_IMAGE_DIR}/**/*.png\", recursive=True) +\n",
    "    glob.glob(f\"{SOURCE_IMAGE_DIR}/**/*.jpg\", recursive=True)\n",
    ")\n",
    "\n",
    "# --- Limit to MAX_IMAGES ---\n",
    "total = min(len(image_paths), MAX_IMAGES)\n",
    "image_paths = image_paths[:total]\n",
    "\n",
    "# --- Calculate split indices ---\n",
    "n_train = int(total * TRAIN_SPLIT)\n",
    "n_val = int(total * VAL_SPLIT)\n",
    "n_test = total - n_train - n_val\n",
    "\n",
    "train_imgs = image_paths[:n_train]\n",
    "val_imgs = image_paths[n_train:n_train + n_val]\n",
    "test_imgs = image_paths[n_train + n_val:]\n",
    "\n",
    "splits = {\n",
    "    \"train\": train_imgs,\n",
    "    \"val\": val_imgs,\n",
    "    \"test\": test_imgs\n",
    "}\n",
    "\n",
    "# --- Copy files with timeframe in name ---\n",
    "for split, paths in splits.items():\n",
    "    for img_path in paths:\n",
    "        relative_img_path = os.path.relpath(img_path, SOURCE_IMAGE_DIR)\n",
    "        tf = relative_img_path.split(os.sep)[0]  # timeframe (e.g. \"1h\")\n",
    "\n",
    "        filename = os.path.basename(img_path)\n",
    "        new_filename = f\"{tf}_{filename}\"\n",
    "\n",
    "        img_out_dir = os.path.join(OUTPUT_BASE_DIR, \"images\", split)\n",
    "        lbl_out_dir = os.path.join(OUTPUT_BASE_DIR, \"labels\", split)\n",
    "        os.makedirs(img_out_dir, exist_ok=True)\n",
    "        os.makedirs(lbl_out_dir, exist_ok=True)\n",
    "\n",
    "        # Copy image\n",
    "        shutil.copy(img_path, os.path.join(img_out_dir, new_filename))\n",
    "\n",
    "        # Copy label if exists\n",
    "        label_rel_path = os.path.splitext(relative_img_path)[0] + \".txt\"\n",
    "        label_full_path = os.path.join(SOURCE_LABEL_DIR, label_rel_path)\n",
    "\n",
    "        if os.path.exists(label_full_path):\n",
    "            new_label_name = os.path.splitext(new_filename)[0] + \".txt\"\n",
    "            shutil.copy(label_full_path, os.path.join(lbl_out_dir, new_label_name))\n",
    "        else:\n",
    "            print(f\"⚠️ Label not found for: {img_path}\")\n",
    "\n",
    "print(\"✅ Dataset split complete. Filenames now include timeframe.\")\n",
    "print(f\"Total: {total} | Train: {len(train_imgs)} | Val: {len(val_imgs)} | Test: {len(test_imgs)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "402d8781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[INIT ERROR] Missing image files:\n[Row 0] Missing 1m_img: None\n[Row 0] Missing 3m_img: None\n[Row 0] Missing 5m_img: /home/morgan-cooper/MSDS Research/StockMarketComputerVisionResearch/reinforcement_learning/images/5m/000001.png\n[Row 0] Missing 15m_img: /home/morgan-cooper/MSDS Research/StockMarketComputerVisionResearch/reinforcement_learning/images/15m/000001.png\n[Row 0] Missing 1h_img: /home/morgan-cooper/MSDS Research/StockMarketComputerVisionResearch/reinforcement_learning/images/1h/000001.png\n[Row 0] Missing 4h_img: /home/morgan-cooper/MSDS Research/StockMarketComputerVisionResearch/reinforcement_learning/images/4h/000001.png\n[Row 0] Missing 1d_img: /home/morgan-cooper/MSDS Research/StockMarketComputerVisionResearch/reinforcement_learning/images/1d/000001.png\n[Row 1] Missing 1m_img: None\n[Row 1] Missing 3m_img: None\n[Row 1] Missing 5m_img: /home/morgan-cooper/MSDS Research/StockMarketComputerVisionResearch/reinforcement_learning/images/5m/000002.png\n... (total missing: 394779)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _init\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Wrap in vectorized and monitored env\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m vec_env = \u001b[43mDummyVecEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmake_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m vec_env = VecMonitor(vec_env)  \u001b[38;5;66;03m# Logs mean reward per episode\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstable_baselines3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvec_env\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VecNormalize\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MSDS Research/StockMarketComputerVisionResearch/.venv/lib/python3.12/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:31\u001b[39m, in \u001b[36mDummyVecEnv.__init__\u001b[39m\u001b[34m(self, env_fns)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, env_fns: \u001b[38;5;28mlist\u001b[39m[Callable[[], gym.Env]]):\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28mself\u001b[39m.envs = [_patch_env(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m env_fns]\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m([\u001b[38;5;28mid\u001b[39m(env.unwrapped) \u001b[38;5;28;01mfor\u001b[39;00m env \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.envs])) != \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.envs):\n\u001b[32m     33\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     34\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou tried to create multiple environments, but the function to create them returned the same instance \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     35\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33minstead of creating different objects. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     40\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mPlease read https://github.com/DLR-RM/stable-baselines3/issues/1151 for more information.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     41\u001b[39m         )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mmake_env.<locals>._init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_init\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     env = \u001b[43mTradingEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeta_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     env = Monitor(env)  \u001b[38;5;66;03m# Wrap with Monitor to log rewards\u001b[39;00m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m env\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/MSDS Research/StockMarketComputerVisionResearch/reinforcement_learning/env/trading_env.py:58\u001b[39m, in \u001b[36mTradingEnv.__init__\u001b[39m\u001b[34m(self, meta_df, image_size, num_actions, leverage, starting_balance, risk_per_trade)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing_images:\n\u001b[32m     57\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join([\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Row \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Missing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_img: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (i, tf, val) \u001b[38;5;129;01min\u001b[39;00m missing_images[:\u001b[32m10\u001b[39m]])\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[INIT ERROR] Missing image files:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m... (total missing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(missing_images)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# --- Account config ---\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28mself\u001b[39m.starting_balance = \u001b[38;5;28mfloat\u001b[39m(starting_balance)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [INIT ERROR] Missing image files:\n[Row 0] Missing 1m_img: None\n[Row 0] Missing 3m_img: None\n[Row 0] Missing 5m_img: /home/morgan-cooper/MSDS Research/StockMarketComputerVisionResearch/reinforcement_learning/images/5m/000001.png\n[Row 0] Missing 15m_img: /home/morgan-cooper/MSDS Research/StockMarketComputerVisionResearch/reinforcement_learning/images/15m/000001.png\n[Row 0] Missing 1h_img: /home/morgan-cooper/MSDS Research/StockMarketComputerVisionResearch/reinforcement_learning/images/1h/000001.png\n[Row 0] Missing 4h_img: /home/morgan-cooper/MSDS Research/StockMarketComputerVisionResearch/reinforcement_learning/images/4h/000001.png\n[Row 0] Missing 1d_img: /home/morgan-cooper/MSDS Research/StockMarketComputerVisionResearch/reinforcement_learning/images/1d/000001.png\n[Row 1] Missing 1m_img: None\n[Row 1] Missing 3m_img: None\n[Row 1] Missing 5m_img: /home/morgan-cooper/MSDS Research/StockMarketComputerVisionResearch/reinforcement_learning/images/5m/000002.png\n... (total missing: 394779)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor\n",
    "\n",
    "from env.trading_env import TradingEnv\n",
    "from models.yolo_extractor import CustomYOLOPolicy\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# writer = SummaryWriter(log_dir=\"./logs/custom\")\n",
    "\n",
    "\n",
    "\n",
    "# --- Load your meta.csv ---\n",
    "meta_df = pd.read_csv(\"./dataset/meta.csv\", parse_dates=[\"timestamp\"])\n",
    "\n",
    "# --- Create your environment ---\n",
    "def make_env():\n",
    "    def _init():\n",
    "        env = TradingEnv(meta_df)\n",
    "        env = Monitor(env)  # Wrap with Monitor to log rewards\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "# Wrap in vectorized and monitored env\n",
    "vec_env = DummyVecEnv([make_env()])\n",
    "vec_env = VecMonitor(vec_env)  # Logs mean reward per episode\n",
    "\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "\n",
    "vec_env = VecNormalize(vec_env, norm_obs=True, norm_reward=True, clip_reward=10.0)\n",
    "\n",
    "# --- Create PPO model ---\n",
    "model = PPO(\n",
    "    policy=CustomYOLOPolicy,\n",
    "    env=vec_env,\n",
    "    verbose=1,\n",
    "    n_steps=128,\n",
    "    batch_size=32,\n",
    "    learning_rate=3e-4,\n",
    "    ent_coef=0.01,\n",
    "    tensorboard_log=\"./logs\"\n",
    ")\n",
    "\n",
    "# After defining your model:\n",
    "# callback = RewardLoggingCallback(writer=writer)\n",
    "\n",
    "\n",
    "# --- Train the model ---\n",
    "\n",
    "model.learn(total_timesteps=100000)\n",
    "\n",
    "vec_env.save(\"vec_normalize.pkl\")\n",
    "\n",
    "# --- Save it ---\n",
    "model.save(\"ppo-yolo-trading\")\n",
    "print(\"✅ Training complete. Model saved to: ppo-yolo-trading\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8b6823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
