{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378effea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../')\n",
    "from utils.load_ticker import load_ticker\n",
    "from utils.clean_data import clean_data\n",
    "\n",
    "\n",
    "df = load_ticker(\n",
    "    base_dir = \"../../parquet_minute/\", \n",
    "    time_col = \"Date\",\n",
    "    symbol_col=\"Symbol\",\n",
    "    seed = 42, \n",
    "    symbol= \"SPY\",\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "\n",
    "df_1m = clean_data(\n",
    "    df=df,\n",
    "    timestamp_col = \"Date\",\n",
    "    symbol_col = \"Symbol\",\n",
    "    drop_duplicate_rows = True,\n",
    "    drop_duplicate_cols = True,\n",
    "    drop_constant_columns = True,\n",
    "    drop_constant_rows = True,\n",
    "    replace_placeholders = True,\n",
    "    placeholders=(\"Null\", \"null\", \"NULL\", \"NaN\", \"nan\", \"NAN\", \"None\", \"none\", \"NONE\"),\n",
    "    fill_missing = True,\n",
    "    convert_numeric = True,\n",
    "    sort_by = \"timestamp\",\n",
    "    verbose = False,\n",
    ")\n",
    "\n",
    "\n",
    "df_1m = df_1m.tail(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400d2e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_generation import MultiTimeframeImageGen\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- prep dataframe ---\n",
    "df_1m['Date'] = pd.to_datetime(df_1m['Date'])\n",
    "df_1m = df_1m.set_index('Date').sort_index()\n",
    "\n",
    "# --- init ---\n",
    "gen = MultiTimeframeImageGen(\n",
    "    [\"1m\", \"3m\", \"5m\", \"15m\", \"1h\", \"4h\", \"1d\"],\n",
    "    base_tf=\"1m\",\n",
    "    window_size=1 * 24 * 60,\n",
    "    output_root=\"dataset\"\n",
    ")\n",
    "\n",
    "# # --- preload only ---\n",
    "# preload_df = df_1m.iloc[:gen.window_size]\n",
    "# for ts, row in tqdm(preload_df.iterrows(),\n",
    "#                     total=len(preload_df),\n",
    "#                     desc=\"Preloading\"):\n",
    "#     row.name = ts\n",
    "#     gen.get_last(row, preload=True)  # no images\n",
    "\n",
    "# --- generate after preload ---\n",
    "generate_df = df_1m.iloc[gen.window_size:]\n",
    "for ts, row in tqdm(generate_df.iterrows(),\n",
    "                    total=len(generate_df),\n",
    "                    desc=\"Generating images\"):\n",
    "    row.name = ts\n",
    "    gen.get_last(row, preload=False)  # saves images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4d4b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def export_tf_video(\n",
    "    root_dir=\"./dataset\",\n",
    "    timeframes_top=(\"1m\", \"3m\", \"5m\", \"15m\"),\n",
    "    timeframes_bottom=(\"1h\", \"4h\", \"1d\"),\n",
    "    output_file=None,\n",
    "    fps=10,\n",
    "    scale=0.7,\n",
    "):\n",
    "    all_timeframes = timeframes_top + timeframes_bottom\n",
    "\n",
    "    if output_file is None:\n",
    "        ts = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        output_file = f\"{root_dir}/videos/tf_{ts}.mp4\"\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "    files = {\n",
    "        tf: sorted(glob.glob(os.path.join(root_dir, tf, \"images\", \"*.png\")))\n",
    "        for tf in all_timeframes\n",
    "    }\n",
    "    num_frames = min(len(lst) for lst in files.values() if lst)\n",
    "\n",
    "    if num_frames == 0:\n",
    "        raise ValueError(\"No frames found in one or more timeframe folders!\")\n",
    "\n",
    "    # Read one sample to determine base height\n",
    "    sample = cv2.imread(files[all_timeframes[0]][0])\n",
    "    if sample is None:\n",
    "        raise ValueError(\"Could not load sample image.\")\n",
    "\n",
    "    base_height = int(sample.shape[0] * scale)\n",
    "    title_height = 30\n",
    "    chart_height = base_height + title_height\n",
    "\n",
    "    # Frame processing with title and black border\n",
    "    def process_frame(path, label):\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            return None\n",
    "        if scale != 1.0:\n",
    "            img = cv2.resize(img, (int(img.shape[1] * scale), int(img.shape[0] * scale)))\n",
    "        h, w = img.shape[:2]\n",
    "        img = cv2.resize(img, (int(w * base_height / h), base_height))\n",
    "\n",
    "        # Title bar\n",
    "        title_bar = np.full((title_height, img.shape[1], 3), 255, dtype=np.uint8)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        text_size = cv2.getTextSize(label, font, 0.6, 1)[0]\n",
    "        text_x = (title_bar.shape[1] - text_size[0]) // 2\n",
    "        text_y = (title_height + text_size[1]) // 2\n",
    "        cv2.putText(title_bar, label, (text_x, text_y), font, 0.6, (0, 0, 0), 1)\n",
    "\n",
    "        # Stack and draw border\n",
    "        combined = np.vstack([title_bar, img])\n",
    "        cv2.rectangle(combined, (0, 0), (combined.shape[1] - 1, combined.shape[0] - 1), (0, 0, 0), 1)\n",
    "        return combined\n",
    "\n",
    "    # Determine output width\n",
    "    top_width = sum(process_frame(files[tf][0], tf).shape[1] for tf in timeframes_top)\n",
    "    bot_width = sum(process_frame(files[tf][0], tf).shape[1] for tf in timeframes_bottom)\n",
    "    out_width = max(top_width, bot_width)\n",
    "    out_height = chart_height * 2\n",
    "\n",
    "    # Init video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_file, fourcc, fps, (out_width, out_height))\n",
    "\n",
    "    # Frame loop\n",
    "    for i in range(num_frames):\n",
    "        row_imgs = []\n",
    "        for tf_group in [timeframes_top, timeframes_bottom]:\n",
    "            frames = []\n",
    "            for tf in tf_group:\n",
    "                img = process_frame(files[tf][i], tf)\n",
    "                if img is not None:\n",
    "                    frames.append(img)\n",
    "            if frames:\n",
    "                row = np.hstack(frames)\n",
    "                if row.shape[1] < out_width:\n",
    "                    pad = np.full((chart_height, out_width - row.shape[1], 3), 255, dtype=np.uint8)\n",
    "                    row = np.hstack([row, pad])\n",
    "                row_imgs.append(row)\n",
    "\n",
    "        full_frame = np.vstack(row_imgs)\n",
    "        out.write(full_frame)\n",
    "\n",
    "    out.release()\n",
    "    print(f\"✅ Video saved: {output_file}\")\n",
    "\n",
    "\n",
    "# ✅ Run this cell in Jupyter\n",
    "export_tf_video(fps=10, scale=0.6)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
